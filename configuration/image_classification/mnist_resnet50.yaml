runtime:
  distribution_strategy: 'mirrored'
  mixed_precision_dtype: 'float16'
  loss_scale: 'dynamic'
  num_gpus: 2
task:
  model:
    num_classes: 10
    input_size: [28, 28, 3]
    backbone:
      type: 'resnet'
      resnet:
        model_id: 50
  losses:
    l2_weight_decay: 0.0001
    one_hot: true
    label_smoothing: 0.1
  train_data:
    tfds_name: 'mnist'
    tfds_split: 'train'
    is_training: true
    global_batch_size: 32
    dtype: 'float16'
    # Autotuning the prefetch buffer size causes OOMs, so set it to a reasonable
    # static value: 32.
    prefetch_buffer_size: 32
  validation_data:
    tfds_name: 'mnist'
    tfds_split: 'test'
    is_training: false
    global_batch_size: 32
    dtype: 'float16'
    drop_remainder: false
    prefetch_buffer_size: 32
trainer:
  train_steps: 1000
  validation_steps: 25
  validation_interval: 625
  steps_per_loop: 625
  summary_interval: 625
  checkpoint_interval: 625
  optimizer_config:
    optimizer:
      type: 'sgd'
      sgd:
        momentum: 0.9
    learning_rate:
      type: 'stepwise'
      stepwise:
        boundaries: [200, 400, 700]
        values: [0.8, 0.08, 0.008, 0.0008]
    warmup:
      type: 'linear'
      linear:
        warmup_steps: 100
